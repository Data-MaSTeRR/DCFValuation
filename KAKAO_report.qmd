---
title: "KAKAO Corp. Investment Report"
toc-location: right
author: HW.S
format: html
date: "`r format(Sys.Date())`" 
editor: visual
---

## 산업분석

*트렌드가 매년 바뀌는 정신없는 IT산업에서 살아남으려면 어떻게 해야할까. 24년 뜨고 있는 IT산업을 분석해 보고 기업들이 추구하고 있는 방향성에 대한 성장성과 수익성을 분석해 보자!*

1\. 생성형 AI의 등장

1.1. AlphGo 이후 등장한 인간을 뛰어넘는 AI ChatGPT

2016년 AlphaGo와 이세돌의 바둑대결은 세상에 큰 충격을 주었습니다. 그 이전까지는 게임에서의 인공지능(AI)이라 하면, 한국에서 특히 유명한 스타크래프트의 AI처럼 패턴이 항상 일정해서 멍청하다고 느껴질 정도로 시시한 존재에 불과하였습니다. 하지만 빠른 연산능력으로 엄청난 데이터를 훈련한 AlphaGo의 등장은 더이상 게임에서 사람의 머리로는 AI를 이길 수 없다는 것을 전세계인들에게 알려주었습니다. 이때부터 전세계의 IT기업들은 AI에 대해 관심을 가지고 개발하기 시작합니다. 이제는 이러한 인공지능의 발전과 함께 진화된 **생성형 AI(Generative AI)**가 창작의 영역을 넘보는 시대가 되었습니다. 위의 AlphaGo와는 달리 ChatGPT, GitHub Copilot, Stable Difusion 등의 생성형 AI들은 그 광범위한 유용성으로 인해 전세계인을 열광하게 만들었습니다. 왜냐하면 누구나 이들과 마치 인간과 의사소통하는 형태로 정보를 얻을 수 있기 때문입니다. 역사적으로 철기시대, 산업혁명, 디지털 혁명 등 인류 패러다임의 전환을 이끈 여러 번의 계기가 있었습니다. 이제 ChatGPT를 시작으로 한 **초거대 생성형 AI**의 출현은 **'새로운 게임 체인저'**로서 인류사 전반에 새바람을 몰고 올 것이라 생각됩니다. 그러면 이 생성형AI란 구체적으로 무엇인가?

**생성형 AI**는 인공지능의 한 분야로, 주어진 데이터를 기반으로 새로운 내용을 생성하거나 생산하는 기술을 가리킵니다. 이는 기존의 데이터나 지식을 바탕으로 새로운 콘텐츠, 이미지, 음악, 텍스트 등을 생성하는 능력을 의미합니다. 생성형 AI는 딥러닝과 기계 학습 알고리즘의 발전으로 많은 관심을 받고 있으며, 다양한 응용 분야에서 활용되고 있습니다. 생성형 AI는 독특하고 독창적인 결과를 생성하기 위해 인간의 행동, 사고 과정 및 창의성을 시뮬레이션할 수 있는 알고리즘을 사용하며, 기계가 입력 매개변수와 이전에 학습한 패턴을 기반으로 새로운 콘텐츠나 데이터를 생성할 수 있습니다. 즉, 기존 데이터를 단순히 가공하거나 분석하는 것이 아니라, 새롭고 독창적인 콘텐츠를 생성하는 AI 접근 방식입니다. 생성형 AI 모델은 패턴을 학습하고 훈련 데이터와 유사한 새로운 출력을 생성하기 위해 대규모 데이터 세트에서 훈련됩니다.

생성형 AI라는 화두를 세상에 쏘아 올린 것은 OpenAI사의 ChatGPT로 GPT-3.5(Generative Pre-trained Transformer) 모델을 기반으로 ‘22년 11월에 출시되었습니다. GPT는 딥러닝을 사용하여 인간과 유사한 텍스트를 생성하는 대규모 자연어 기술입니다. ChatGPT는 5일 만에 이용자가 100만 명이 넘었고 40일 만에 1,000만 명이 가입했으며, 또 두 달 만에 1억 명을 훌쩍 뛰어넘은 이용자를 기록했습니다. 100만 명의 이용자를 확보하는데 Apple iPhone은 두 달 이상이 걸렸고, Facebook은 10개월, Netflix는 3년 이상이 걸렸으니, 일각에서는 ChatGPT를 '괴물'로 표현하기까지 합니다. 출시 이후, OpenAI는 4개월 만에 GPT-4라는 새로운 대형언어모델(LLM, Large Language Model)을 출시했으며, 이 모델은 뚜렷하게 개선된 능력을 갖추고 있습니다. GPT-4는 사진 속 사람의 손 글씨나 메모를 인식해 사용자의 요청을 수행하고, 지정한 대로 PPT 자료를 만들어 주는 것은 물론 냉장고 속 재료 사진만으로 요리 레시피를 소개합니다. 또한, 변호사 자격시험에 합격하고 미국 생물학 올림피아드에서 87점(상위 1%)의 성적을 낼 정도로 똑똑해졌습니다. OpenAI는 GPT-4에 대해 "인간의 수준을 가졌다"라고 자평했고, 일반 대화에서도 인간과 큰 차이를 느끼지 못하는 수준이 되었습니다.

1.2. 생성형 AI의 가치사슬

-   컴퓨터 하드웨어

    생성형 AI는 콘텐츠를 생성하기 위해 많은 지식이 필요합니다. 예를 들어, OpenAI의 GPT-3는 약 45테라바이트의 텍스트 데이터로 훈련되었습니다. 이러한 작업량은 수십억 개의 매개변수를 병렬로 처리할 수 있는 "가속기" 칩을 가지고 있는 그래픽처리장치(GPU)나 텐서처리장치(TPU)로 구성된 대규모 클러스터를 필요로 합니다. 생성형 AI 모델의 훈련이 완료되면, 기업은 대규모 클러스터를 사용하여 모델을 맞춤화(조정)하고, 이러한 컴퓨팅 파워를 요구하는 모델을 애플리케이션 내에서 실행할 수도 있습니다. 그러나, 초기 훈련과 비교하면 이후에는 훨씬 적은 컴퓨팅 파워가 필요합니다. 작은 규모의 플레이어들도 몇몇 존재하지만, 이러한 특수화된 AI 프로세서의 설계와 생산은 집중화되어 있으며, NVIDIA와 Google이 칩 디자인 시장을 지배하고 있습니다.

-   클라우드 플랫폼

    GPU와 TPU는 비싸고 부족한 자원이기 때문에 대부분의 기업들이 대규모 AI 모델을 구축하고 조정 및 실행하는 작업은 클라우드에서 수행됩니다. 이를 통해 기업은 필요에 따라 계산 능력에 쉽게 접근하고 비용을 관리할 수 있습니다. 주요 클라우드 업체들은 생성형 AI 워크로드를 실행하고 하드웨어/칩의 우선적 액세스를 위한 가장 포괄적인 플랫폼을 보유하고 있습니다.

-   파운데이션 모델

    **생성형 AI의 핵심**에는 **파운데이션 모델**이 있습니다. 파운데이션 모델은 인간 뇌에 연결된 수십억 개의 뉴런에 영감을 받은 확장된 인공신경망을 포함하고 있습니다. 파운데이션 모델은 딥러닝이라는 용어로 불리며, 신경망 내에 있는 많은 깊은 층을 암시합니다. 딥러닝은 AI의 최신 진보를 이끌어 온 기술이지만, 생성형 AI 애플리케이션을 구동하는 파운데이션 모델은 딥러닝에서의 큰 진보입니다. 이전의 딥러닝 모델과는 달리, 매우 크고 다양한 형태의 비정형 데이터를 처리하고 여러 작업을 수행할 수 있습니다.\
    \
    대규모 딥러닝 모델은 특정 유형의 콘텐츠를 생성하기 위해 사전 훈련되고 다양한 작업을 지원하기 위해 활용됩니다. 파운데이션 모델이 개발되면, 이를 기반으로 애플리케이션을 구축하여 콘텐츠를 생성할 수 있습니다. OpenAI의 GPT-3와 GPT-4 같은 파운데이션 모델은 ChatGPT부터 Jasper와 Copy.ai 같은 수십 개의 애플리케이션을 지원합니다. 파운데이션 모델은 대용량 데이터 세트를 기반으로 훈련되고, Wikipedia, 정부 사이트, 소셜 미디어, 책 등의 공개 데이터뿐만 아니라 대규모 데이터베이스의 비공개 데이터를 포함할 수 있습니다. 또한, 파운데이션 모델을 개발하기 위해서는 여러 영역에서 깊은 전문 지식이 필요합니다. 데이터 준비, 목표로 하는 출력을 생성할 수 있는 모델 아키텍처 선택, 모델 훈련, 그리고 출력 개선을 위한 모델 튜닝이 포함됩니다. 모델 튜닝은 훈련된 모델의 출력 품질을 평가하고 이를 모델에 피드백으로 제공하여 학습할 수 있도록 하는 과정입니다.\
    \
    오늘날, 특히 파운데이션 모델의 훈련은 반복적인 과정이며 상당한 컴퓨팅 자원이 필요하기 때문에 많은 비용이 듭니다. 모델의 훈련 과정의 초반에는 일반적으로 무작위 결과를 출력합니다. 원하는 수준의 정확도를 위해 훈련 알고리즘은 신경망의 가중치를 조정하고, 이러한 과정을 수백만 번 수행해야 할 수도 있습니다. 현재, 이러한 훈련 작업은 수백만 달러의 비용이 들고 수개월이 소요될 수 있습니다. 예를 들어, OpenAI의 GPT-3를 훈련하는 데는 400만\~1,200만 달러가 소요된다고 추정됩니다. 결과적으로, 시장은 소수의 거대 기업과 투자를 받은 스타트업에 의해 지배되고 있습니다. 그러나, 일부 작업에 효과적인 결과를 제공할 수 있는 **더 작은 모델과 더 효율적인 방식의 훈련 방법**을 개발하기 위한 노력이 진행 중이며, 몇몇 스타트업이 **자체 대형언어모델(LLM, Large Language Model)**을 구축하고 훈련하는 데 성공했습니다. 또한, 대부분의 대기업은 더 높은 수준의 데이터 보안 및 개인정보 보호를 위해 LLM을 자사 환경에서 동작하길 원하고 있으며, Cohere와 같은 기업은 이미 LLM을 중심으로 이러한 서비스를 제공하고 있습니다.

-   모델허브 및 MLOps

    파운데이션 모델을 활용하여 애플리케이션을 구축하기 위해서는 우선 파운데이션 모델을 저장하고 액세스할 수 있는 장소가 필요합니다. 또한, 파운데이션 모델을 적용하고 애플리케이션 내에 배포하기 위한 **특화된 MLOps 도구 및 기술**이 필요합니다. 여기에는 추가 훈련 데이터를 통합하고 레이블을 지정하거나 애플리케이션이 모델과 상호 작용할 수 있는 API를 구축하는 기능이 포함됩니다. **모델 허브**는 이러한 서비스를 제공합니다.\
    \
    **소스코드가 공개되지 않은 모델**의 경우, 라이선싱 계약을 통해 모델에 액세스할 수 있도록 API를 제공하고, 때로는 제공업체가 MLOps 기능을 제공하여 모델을 조정하고 다양한 애플리케이션에 배포할 수 있도록 합니다. **오픈소스 모델**의 경우, 다양한 서비스를 제공하기 위한 독립적인 모델 허브가 등장하고 있습니다. 일부 모델 허브는 단지 모델을 집계하는 역할만 하며, 다른 개발자들이 커스터마이징한 모델을 포함한 다양한 파운데이션 모델에 대해 엑세스할 수 있도록 합니다. 이후, AI팀은 모델을 서버로 다운로드하고, 세부 조정하여 애플리케이션에 배포할 수 있습니다. 반면, Hugging Face나 Amazon Web Services와 같은 모델 허브는 모델에 액세스할 수 있는 뿐만 아니라, 독점(소유) 데이터를 활용하여 파운데이션 모델을 조정(Tune)하고 애플리케이션 내에 배포하는 전문 지식을 포함한 전체적인 MLOps 기능을 제공할 수 있습니다. 후자의 모델 허브는 기업들이 생성형 AI를 활용에 있어 내부 인재와 인프라가 부족한 기업에서 큰 도움을 줍니다. 아마존의 경우, AWS 사용자가 Anthropic사의 Claude와 Stability사의 Stable Diffusion 등의 다양한 모델을 활용할 수 있는 새로운 서비스인 베드록(Bedrock)을 소개했으며, 월스트리트저널에서는 아마존이 비즈니스를 AI와 통합하려는 회사가 가장 적합한 것을 선택/활용할 수 있는 중립 플랫폼을 표방하고 있다고 언급했습니다.

-   Application

-   Service

    생성형 AI의 활용을 위한 서비스 및 전문 지식 서비스를 제공합니다. 기존 AI 서비스 제공업체들은 생성형 AI 시장을 위한 서비스를 발전시킬 것이며, 특정 기능(예. 고객 서비스 워크플로우), 산업(예. 제약), 다양한 맥락에서 효과적인 루프 구축 방법 등에서 생성형 AI를 적용하기 위한 특수한 지식을 가진 특화된 업체들도 시장에 진출할 것으로 예상됩니다.

1.3. 생성형AI의 성장성에 관한 통계자료

글로벌 연구 조사기업인 Gartner에 따르면 글로벌 기업 임원 2,544명을 대상으로 설문조사를 실시한 결과, 경영진의 45%가 ChatGPT가 인공지능(AI) 투자를 늘리도록 자극했으며, 생성형 AI의 주요 투자 목적으로 "고객 경험, 매출 성장, 비용 최적화"를 꼽았습니다. 경영진의 70%가 현재 생성형 AI에 대해 탐색 단계(Exploration Mode)에 있고, 19%는 Pilot이나 Production 단계에 있다고 답변했습니다. 또한, 경영진의 68%가 생성형 AI의 이점이 위험보다 크다고 생각하는 반면, 위험이 이점보다 크다고 생각하는 비율은 5%에 불과했습니다. 즉, 생성형AI 산업은 아직 탐색단계로서 성장가능성이 무궁무진한 시장이고 많은 임원들이 긍정적으로 생각하고 있다는 것을 알 수 있습니다.

```{r, echo=FALSE}

amounts = c(38, 26, 17, 7, 12)
names = c("Customer Experience", "Revenue Growth", "Cost Optimization", "Business Continuity", "None of the above")
data = data.frame(amounts, names)
pie(data$amounts, labels = as.character(data$names))
```

```{python}
import FundamentalAnalysis as fa 
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import yfinance as yf

ticker = "AMD" #ticker name
api = "384de232a09606f8ff4de3489690dc4c" #api key

#get company profile for beta calculation and marketcap
profile = fa.profile(ticker, api)
quote = fa.quote(ticker, api)

#FMP gives the dates reversed and hence the need for the .iloc in all the data calls
#get the cash flow, income statement, and balance sheet
cf = fa.cash_flow_statement(ticker, api).iloc[:,::-1]
ins = fa.income_statement(ticker, api).iloc[:,::-1]
bs = fa.balance_sheet_statement(ticker, api).iloc[:,::-1]

year = "2019" #set year


```

2\. 기하급수적으로 늘어나고 있는 Data시대에서 살아남기

2.1. 클라우드 서비스

2.2.

## 기업분석

-   톡비즈

-   포털비즈

-   카카오T, 카카오페이

-   게임

-   멜론

-   클라우드

카카오는 ‘코-GPT’라는 챗GPT의 한국어 버전을 앞세웠습니다. 챗GPT의 문제점 중 하나는 한국어를 제대로 이해하지 못하여 종종 엉뚱한 대답이 나온다는 건데요. 코-GPT는 이러한 챗GPT의 문제점을 해소하기 위해 출시되었습니다. 제시된 한국어를 사전적, 문맥적으로 이해하고 사용자의 의도에 맞춘 문장을 생성해 제공해내는 거죠. 또 대국민 앱인 카카오톡과 연계하는 방안도 마련하고 있습니다. 카카오톡 비즈니스 서비스와 AI서비스를 함께 활용한다면 더욱 시너지를 낼 수 있을 거란 계산이죠. 

## 가치평가

-   매출분석

-   

## 
